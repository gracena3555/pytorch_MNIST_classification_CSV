{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f074406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드에 필요한 모듈 import\n",
    "import os\n",
    "from typing import Tuple, Sequence, Callable\n",
    "import csv\n",
    "import cv2 # opencv-python 컴퓨터비전\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add6940",
   "metadata": {},
   "source": [
    "Unbounded Error : https://sikaleo.tistory.com/99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0276083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 만들기\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    # 전체 초기화 함수 : 초기화하기에 return이 존재하지 않음\n",
    "    def __init__(self, dir, image_ids, transforms):\n",
    "        self.dir = dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # 라벨\n",
    "        self.labels = {}\n",
    "        with open(image_ids, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                self.labels[int(row[0])] = list(map(int, row[1:]))\n",
    "        self.image_ids = list(self.labels.keys())\n",
    "    \n",
    "    # 사용자함수는 return이 존재\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    # 이미지 인덱스로부터 id를 가져와서 파일을 open\n",
    "    def __getitem__(self, index):\n",
    "        global image\n",
    "        image_id = self.image_ids[index]\n",
    "        # png이미지를 rgh로 바꾸고, id가 5자리\n",
    "        image = image.open(os.path.join(\n",
    "            self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB') # 인자들을 불러오는 과정 \n",
    "        target = np.array(self.labels.get(image_id)).astype(np.float32)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d39ee21",
   "metadata": {},
   "source": [
    "RandomHorizontalFlip\n",
    "- p (float) – probability of the image being flipped. Default value is 0.5\n",
    "- ref_site: https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e510d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 augmentation\n",
    "# Resize, Cropping, Rotate 등 다른 augmentaion 방법도 사용할 수 \n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p=0이면, 뒤집지 않는다 # default=0.5\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(), # 아래 둘은 일반적으로 사용(ToTensor, Normalize)\n",
    "    transforms.Normalize(\n",
    "    [0.485,0.456,0.406], # mean(평균)\n",
    "    [0.229,0.224,0.225]) # std(분산)\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    [0.485,0.456,0.406],\n",
    "    [0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb0903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 데이터셋 불러오기\n",
    "trainset = Dataset('data/train', 'data/train.csv', transforms_train)\n",
    "testset = Dataset('data/test', 'data/test.csv', transforms_test)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=256, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8649377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Model                                         --                        --\n",
      "├─ResNet: 1-1                                 [1, 1000]                 --\n",
      "│    └─Conv2d: 2-1                            [1, 64, 128, 128]         9,408\n",
      "│    └─BatchNorm2d: 2-2                       [1, 64, 128, 128]         128\n",
      "│    └─ReLU: 2-3                              [1, 64, 128, 128]         --\n",
      "│    └─MaxPool2d: 2-4                         [1, 64, 64, 64]           --\n",
      "│    └─Sequential: 2-5                        [1, 256, 64, 64]          --\n",
      "│    │    └─Bottleneck: 3-1                   [1, 256, 64, 64]          75,008\n",
      "│    │    └─Bottleneck: 3-2                   [1, 256, 64, 64]          70,400\n",
      "│    │    └─Bottleneck: 3-3                   [1, 256, 64, 64]          70,400\n",
      "│    └─Sequential: 2-6                        [1, 512, 32, 32]          --\n",
      "│    │    └─Bottleneck: 3-4                   [1, 512, 32, 32]          379,392\n",
      "│    │    └─Bottleneck: 3-5                   [1, 512, 32, 32]          280,064\n",
      "│    │    └─Bottleneck: 3-6                   [1, 512, 32, 32]          280,064\n",
      "│    │    └─Bottleneck: 3-7                   [1, 512, 32, 32]          280,064\n",
      "│    └─Sequential: 2-7                        [1, 1024, 16, 16]         --\n",
      "│    │    └─Bottleneck: 3-8                   [1, 1024, 16, 16]         1,512,448\n",
      "│    │    └─Bottleneck: 3-9                   [1, 1024, 16, 16]         1,117,184\n",
      "│    │    └─Bottleneck: 3-10                  [1, 1024, 16, 16]         1,117,184\n",
      "│    │    └─Bottleneck: 3-11                  [1, 1024, 16, 16]         1,117,184\n",
      "│    │    └─Bottleneck: 3-12                  [1, 1024, 16, 16]         1,117,184\n",
      "│    │    └─Bottleneck: 3-13                  [1, 1024, 16, 16]         1,117,184\n",
      "│    └─Sequential: 2-8                        [1, 2048, 8, 8]           --\n",
      "│    │    └─Bottleneck: 3-14                  [1, 2048, 8, 8]           6,039,552\n",
      "│    │    └─Bottleneck: 3-15                  [1, 2048, 8, 8]           4,462,592\n",
      "│    │    └─Bottleneck: 3-16                  [1, 2048, 8, 8]           4,462,592\n",
      "│    └─AdaptiveAvgPool2d: 2-9                 [1, 2048, 1, 1]           --\n",
      "│    └─Linear: 2-10                           [1, 1000]                 2,049,000\n",
      "├─Linear: 1-2                                 [1, 26]                   26,026\n",
      "===============================================================================================\n",
      "Total params: 25,583,058\n",
      "Trainable params: 25,583,058\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 5.34\n",
      "===============================================================================================\n",
      "Input size (MB): 0.79\n",
      "Forward/backward pass size (MB): 232.27\n",
      "Params size (MB): 102.33\n",
      "Estimated Total Size (MB): 335.39\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# pretrained된 resnet50 네트워크 불러오기\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = (resnet50(pretrained=True))\n",
    "        self.classifier = nn.Linear(1000,26)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Model().to(device)\n",
    "print(summary(model, input_size=(1,3,256,256), verbose=0))\n",
    "\n",
    "# .pth: 저장된 모델의 확장자 > netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f79f697",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16504/504351428.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16504/1006616650.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mimage_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# png이미지를 rgh로 바꾸고, id가 5자리\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         image = image.open(os.path.join(\n\u001b[0m\u001b[0;32m     28\u001b[0m             self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB') # 인자들을 불러오는 과정 \n\u001b[0;32m     29\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# 학습을 위한 코드\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            outputs = outputs > 0.5\n",
    "            acc = (outputs == targets).float().mean()\n",
    "            print(f'{epoch}:{loss.item():.5f}, {acc.item():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa43017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d2a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f3f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
